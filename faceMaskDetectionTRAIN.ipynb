{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"faceMaskDetectionTRAIN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNIiJ8M/BQ1FTmz7EBfNDRW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-D4e2GDXWuDv","executionInfo":{"status":"ok","timestamp":1648234307504,"user_tz":300,"elapsed":23220,"user":{"displayName":"Fernando Berrospi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08160125661310283224"}},"outputId":"39413599-ebf5-45f2-898c-78ebd028df6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive,files\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from keras.callbacks import ModelCheckpoint\n","import numpy as np"],"metadata":{"id":"AetTSriCXBGC","executionInfo":{"status":"ok","timestamp":1648234577447,"user_tz":300,"elapsed":310,"user":{"displayName":"Fernando Berrospi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08160125661310283224"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["path = '/content/drive/Othercomputers/My MacBook Pro/projects/python/faceMaskDetection'"],"metadata":{"id":"oj2lDaFLZ1kt","executionInfo":{"status":"ok","timestamp":1648236234554,"user_tz":300,"elapsed":274,"user":{"displayName":"Fernando Berrospi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08160125661310283224"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#BUILDING THE NN\n","#CNN of 2 pairs of Conv2D and MaxPool layers to extract data.\n","model = Sequential()\n","\n","model.add(Conv2D(100, (3,3), activation = 'relu', input_shape = (150, 150, 3)))\n","model.add(MaxPooling2D(2,2))\n","\n","model.add(Conv2D(100, (3,3), activation = 'relu'))\n","model.add(MaxPooling2D(2,2))\n","\n","#Add flatten and dropout layers to model to convert data to 1D. Finally add 2 dense llayers for clasificaiton\n","\n","model.add(Flatten())\n","model.add(Dropout(0.5))\n","model.add(Dense(50, activation = 'relu'))\n","model.add(Dense(2, activation = 'softmax'))\n","\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])"],"metadata":{"id":"8ISCJoOBb4Jt","executionInfo":{"status":"ok","timestamp":1648236109945,"user_tz":300,"elapsed":250,"user":{"displayName":"Fernando Berrospi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08160125661310283224"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#TRAIN AND TEST DATA AUGMENTATION\n","train_path = path + '/dataset/train/'\n","train_datagen = ImageDataGenerator(rescale = 1.0/255, \n","                                  rotation_range = 40,\n","                                  width_shift_range = 0.2,\n","                                  height_shift_range = 0.2,\n","                                  shear_range = 0.2,\n","                                  zoom_range = 0.2,\n","                                  horizontal_flip = True,\n","                                  fill_mode = 'nearest')\n","\n","train_generator = train_datagen.flow_from_directory(train_path,\n","                                                    batch_size = 10,\n","                                                    target_size = (150, 150))\n","\n","test_path = path + '/dataset/test'\n","test_datagen = ImageDataGenerator(rescale = 1.0/255)\n","\n","test_generator = test_datagen.flow_from_directory(test_path, \n","                                                  batch_size=10, \n","                                                  target_size=(150, 150))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K2-fHFYne_bm","executionInfo":{"status":"ok","timestamp":1648240234631,"user_tz":300,"elapsed":273,"user":{"displayName":"Fernando Berrospi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08160125661310283224"}},"outputId":"ee0f1936-ed29-46e5-ca90-49f5ad483f07"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1315 images belonging to 2 classes.\n","Found 194 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["#CHECKPOINT TO KEEP THE BEST MODEL\n","checkpoint = ModelCheckpoint(path + '/models/' + 'faceMaskModel-{epoch:02d}.model',\n","                             monitor = 'val_loss',\n","                             verbose = 0,\n","                             save_best_only = True,\n","                             mode = 'auto')"],"metadata":{"id":"ocC1QwfaiGo9","executionInfo":{"status":"ok","timestamp":1648242201173,"user_tz":300,"elapsed":261,"user":{"displayName":"Fernando Berrospi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08160125661310283224"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#TRAINING\n","history = model.fit(train_generator,\n","                    epochs = 10,\n","                    validation_data = test_generator,\n","                    callbacks = [checkpoint])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-E43cZJyw_HP","executionInfo":{"status":"ok","timestamp":1648243688595,"user_tz":300,"elapsed":1476132,"user":{"displayName":"Fernando Berrospi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08160125661310283224"}},"outputId":"254a84c7-e43c-4f97-ff05-8cec867f2233"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","132/132 [==============================] - ETA: 0s - loss: 0.1410 - acc: 0.9468INFO:tensorflow:Assets written to: /content/drive/Othercomputers/My MacBook Pro/projects/python/faceMaskDetection/models/faceMaskModel-01.model/assets\n","132/132 [==============================] - 144s 1s/step - loss: 0.1410 - acc: 0.9468 - val_loss: 0.0506 - val_acc: 0.9742\n","Epoch 2/10\n","132/132 [==============================] - ETA: 0s - loss: 0.1532 - acc: 0.9422INFO:tensorflow:Assets written to: /content/drive/Othercomputers/My MacBook Pro/projects/python/faceMaskDetection/models/faceMaskModel-02.model/assets\n","132/132 [==============================] - 142s 1s/step - loss: 0.1532 - acc: 0.9422 - val_loss: 0.0263 - val_acc: 0.9948\n","Epoch 3/10\n","132/132 [==============================] - 142s 1s/step - loss: 0.1505 - acc: 0.9498 - val_loss: 0.0355 - val_acc: 0.9897\n","Epoch 4/10\n","132/132 [==============================] - ETA: 0s - loss: 0.1267 - acc: 0.9506INFO:tensorflow:Assets written to: /content/drive/Othercomputers/My MacBook Pro/projects/python/faceMaskDetection/models/faceMaskModel-04.model/assets\n","132/132 [==============================] - 142s 1s/step - loss: 0.1267 - acc: 0.9506 - val_loss: 0.0189 - val_acc: 1.0000\n","Epoch 5/10\n","132/132 [==============================] - 141s 1s/step - loss: 0.1350 - acc: 0.9498 - val_loss: 0.0416 - val_acc: 0.9845\n","Epoch 6/10\n","132/132 [==============================] - 141s 1s/step - loss: 0.1317 - acc: 0.9460 - val_loss: 0.0312 - val_acc: 0.9897\n","Epoch 7/10\n","132/132 [==============================] - 140s 1s/step - loss: 0.1411 - acc: 0.9445 - val_loss: 0.0743 - val_acc: 0.9845\n","Epoch 8/10\n","132/132 [==============================] - ETA: 0s - loss: 0.1301 - acc: 0.9490INFO:tensorflow:Assets written to: /content/drive/Othercomputers/My MacBook Pro/projects/python/faceMaskDetection/models/faceMaskModel-08.model/assets\n","132/132 [==============================] - 141s 1s/step - loss: 0.1301 - acc: 0.9490 - val_loss: 0.0143 - val_acc: 1.0000\n","Epoch 9/10\n","132/132 [==============================] - 140s 1s/step - loss: 0.1258 - acc: 0.9574 - val_loss: 0.0273 - val_acc: 0.9897\n","Epoch 10/10\n","132/132 [==============================] - 140s 1s/step - loss: 0.1102 - acc: 0.9551 - val_loss: 0.0193 - val_acc: 1.0000\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"QFDPHOqL5Dyu"},"execution_count":null,"outputs":[]}]}